{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "np.set_printoptions(threshold=np.inf, precision=2)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dfci_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_start = df\n",
    "df_end = df\n",
    "df_start['timestamp'] = df_start['start_time']\n",
    "df_end['timestamp'] = df_end['end_time']\n",
    "df_start['event_new'] = df_start['event'].astype(str)+ '_start'\n",
    "df_end['event_new'] = df_end['event'].astype(str)+ '_end'\n",
    "df = pd.concat([df_start, df_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['case_id', 'timestamp']).reset_index()\n",
    "df['id'] = df['case_id'] \n",
    "df['state'] = df_start['event_new']\n",
    "df['event_new'] = None\n",
    "df['case_id'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 525824\n",
      "10000 out of 525824\n",
      "20000 out of 525824\n",
      "30000 out of 525824\n",
      "40000 out of 525824\n",
      "50000 out of 525824\n",
      "60000 out of 525824\n",
      "70000 out of 525824\n",
      "80000 out of 525824\n",
      "90000 out of 525824\n",
      "100000 out of 525824\n",
      "110000 out of 525824\n",
      "120000 out of 525824\n",
      "130000 out of 525824\n",
      "140000 out of 525824\n",
      "150000 out of 525824\n",
      "160000 out of 525824\n",
      "170000 out of 525824\n",
      "180000 out of 525824\n",
      "190000 out of 525824\n",
      "200000 out of 525824\n",
      "210000 out of 525824\n",
      "220000 out of 525824\n",
      "230000 out of 525824\n",
      "240000 out of 525824\n",
      "250000 out of 525824\n",
      "260000 out of 525824\n",
      "270000 out of 525824\n",
      "280000 out of 525824\n",
      "290000 out of 525824\n",
      "300000 out of 525824\n",
      "310000 out of 525824\n",
      "320000 out of 525824\n",
      "330000 out of 525824\n",
      "340000 out of 525824\n",
      "350000 out of 525824\n",
      "360000 out of 525824\n",
      "370000 out of 525824\n",
      "380000 out of 525824\n",
      "390000 out of 525824\n",
      "400000 out of 525824\n",
      "410000 out of 525824\n",
      "420000 out of 525824\n",
      "430000 out of 525824\n",
      "440000 out of 525824\n",
      "450000 out of 525824\n",
      "460000 out of 525824\n",
      "470000 out of 525824\n",
      "480000 out of 525824\n",
      "490000 out of 525824\n",
      "500000 out of 525824\n",
      "510000 out of 525824\n",
      "520000 out of 525824\n"
     ]
    }
   ],
   "source": [
    "df['next_state'] = ''\n",
    "df['next_time'] = 0\n",
    "df['next_dur'] = 0\n",
    "num_rows = len(df)\n",
    "for i in range(0, num_rows - 1):\n",
    "    if (i % 10000 == 0): print(str(i) + ' out of ' + str(num_rows))\n",
    "\n",
    "    if df.at[i, 'id'] == df.at[i + 1, 'id']:\n",
    "        df.at[i, 'next_state'] = df.at[i + 1, 'state']\n",
    "        df.at[i, 'next_time'] = df.at[i + 1, 'timestamp']\n",
    "        df.at[i, 'next_dur'] = df.at[i + 1, 'timestamp'] - df.at[i, 'timestamp']\n",
    "    else:\n",
    "        df.at[i, 'next_state'] = 99\n",
    "        df.at[i, 'next_time'] = df.at[i, 'timestamp']\n",
    "        df.at[i, 'next_dur'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 out of 525824\n",
      "20000 out of 525824\n",
      "30000 out of 525824\n",
      "40000 out of 525824\n",
      "50000 out of 525824\n",
      "60000 out of 525824\n",
      "70000 out of 525824\n",
      "80000 out of 525824\n",
      "90000 out of 525824\n",
      "100000 out of 525824\n",
      "110000 out of 525824\n",
      "120000 out of 525824\n",
      "130000 out of 525824\n",
      "140000 out of 525824\n",
      "150000 out of 525824\n",
      "160000 out of 525824\n",
      "170000 out of 525824\n",
      "180000 out of 525824\n",
      "190000 out of 525824\n",
      "200000 out of 525824\n",
      "210000 out of 525824\n",
      "220000 out of 525824\n",
      "230000 out of 525824\n",
      "240000 out of 525824\n",
      "250000 out of 525824\n",
      "260000 out of 525824\n",
      "270000 out of 525824\n",
      "280000 out of 525824\n",
      "290000 out of 525824\n",
      "300000 out of 525824\n",
      "310000 out of 525824\n",
      "320000 out of 525824\n",
      "330000 out of 525824\n",
      "340000 out of 525824\n",
      "350000 out of 525824\n",
      "360000 out of 525824\n",
      "370000 out of 525824\n",
      "380000 out of 525824\n",
      "390000 out of 525824\n",
      "400000 out of 525824\n",
      "410000 out of 525824\n",
      "420000 out of 525824\n",
      "430000 out of 525824\n",
      "440000 out of 525824\n",
      "450000 out of 525824\n",
      "460000 out of 525824\n",
      "470000 out of 525824\n",
      "480000 out of 525824\n",
      "490000 out of 525824\n",
      "500000 out of 525824\n",
      "510000 out of 525824\n",
      "520000 out of 525824\n"
     ]
    }
   ],
   "source": [
    "df['elapsed_time'] = 0\n",
    "df['total_time'] = 0\n",
    "df['remaining_time'] = 0\n",
    "df['history'] = \"\"\n",
    "ids = []\n",
    "total_Times = []\n",
    "num_rows = len(df)\n",
    "temp_elapsed = 0\n",
    "prefix = str(df.at[0, 'event'])\n",
    "\n",
    "for i in range(1, num_rows):\n",
    "    if (i % 10000 == 0): print(str(i) + ' out of ' + str(num_rows))\n",
    "\n",
    "    if df.at[i, 'id'] == df.at[i - 1, 'id']:\n",
    "        temp_elapsed += df.at[i - 1, 'next_dur']\n",
    "        df.at[i, 'elapsed_time'] = temp_elapsed\n",
    "        prefix = prefix + '_' + str(df.at[i, 'event'])\n",
    "        df.at[i, 'history'] = prefix\n",
    "    else:\n",
    "        ids.append(df.at[i - 1, 'id'])\n",
    "        total_Times.append(temp_elapsed)\n",
    "        temp_elapsed = 0\n",
    "        prefix = str(df.at[i, 'event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ids.append(df.at[num_rows - 1, 'id'])\n",
    "# total_Times.append(df.at[num_rows - 1, 'elapsed_time'])\n",
    "# for i in range(0, num_rows):\n",
    "#     if (i % 10000 == 0): print(str(i) + ' out of ' + str(num_rows))\n",
    "#     try:\n",
    "#         ind = ids.index(df.at[i, 'id'])\n",
    "#         total_ = total_Times[ind]\n",
    "#         df.at[i, 'total_time'] = total_\n",
    "#         df.at[i, 'remaining_time'] = total_ - df.at[i, 'elapsed_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['finish_time'] = df.groupby('id')['elapsed_time'].transform('last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['remaining_time'] = df['finish_time'] - df['elapsed_time']\n",
    "df['remaining_time_q'] = pd.qcut(df['remaining_time'], 10, labels = [1,2,3,4,5] ,duplicates='drop') #creates 5 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split_ts_ordered(df,test_size):\n",
    "    train_size = int((1-test_size)*len(df.index))\n",
    "    train_df =df.head(train_size)\n",
    "    test_df = df.tail(len(df.index) - train_size)\n",
    "    print('Splits:')\n",
    "    print(train_size)\n",
    "    print(len(df.index) - train_size)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_vanila_x = df.sort_values(['id', 'remaining_time'], ascending=False).groupby('id')['event'].apply(np.array)\n",
    "df_vanila_y = df.sort_values(['id', 'remaining_time'],ascending=False).groupby('id')['remaining_time_q'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits:\n",
      "119523\n",
      "29881\n",
      "Splits:\n",
      "119523\n",
      "29881\n"
     ]
    }
   ],
   "source": [
    "train_df_x, test_df_x = train_test_split_ts_ordered(df_vanila_x, test_size=0.2)\n",
    "train_df_y, test_df_y = train_test_split_ts_ordered(df_vanila_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "longest = df.groupby(['id']).count()['state'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_x = pad_sequences(train_df_x, maxlen=longest, value=0.)\n",
    "test_df_x = pad_sequences(test_df_x, maxlen=longest, value=0.)\n",
    "train_df_y = pad_sequences(train_df_y, maxlen=longest, value=0.)\n",
    "test_df_y = pad_sequences(test_df_y, maxlen=longest, value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119523, 16)\n",
      "(119523, 16)\n"
     ]
    }
   ],
   "source": [
    "print(train_df_y.shape)\n",
    "print(train_df_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (train_df_y/60).hist(bins=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_y = to_categorical(train_df_y, nb_classes = 6)\n",
    "test_df_y = to_categorical(test_df_y, nb_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = tflearn.input_data(shape=[None] + list(train_df_x.shape)[1:])\n",
    "net = tflearn.embedding(net, input_dim=list(train_df_x.shape)[0], output_dim=128)\n",
    "net = tflearn.lstm(net, 128, activation='relu', dynamic=True)\n",
    "net = tflearn.fully_connected(net, 6, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dc3ee0f5542c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(train_df_x, train_df_y, validation_set=(test_df_x, test_df_y), show_metric=True,\n\u001b[0;32m----> 3\u001b[0;31m           batch_size=32)\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\avi\\Anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[1;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[0;32m--> 184\u001b[0;31m                                       self.targets)\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mval_feed_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\avi\\Anaconda3\\lib\\site-packages\\tflearn\\utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[0;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[1;31m# If a dict is provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(train_df_x, train_df_y, validation_set=(test_df_x, test_df_y), show_metric=True,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
